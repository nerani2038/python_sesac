{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 실습 4~7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 4. 사이트내에 인기검색종목과 주요해외지수를 각각 크롤링하여 종목명과 주가지수를 아래와 같이 리스트로 정리해주세요. \n",
    "\n",
    "결과 : \n",
    "[['써니전자', '5,000'], ['삼성전자', '55,200'], ['안랩', '81,000'], ['케이엠더블..', '57,300'], ['피피아이', '12,600’], \n",
    "['KT&G', '92,500'], ['삼성전자우', '45,600'], ['대양금속', '10,550'], ['SK하이닉스', '94,700'], ['SK텔레콤', '234,000’]]\n",
    "\n",
    "[['다우산업', '28,647.43'], ['나스닥', '9,015.03'], ['홍콩H', '11,320.56'], ['상해종합', '3,085.20'], ['니케이225', '23,656.62']]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['써니전자', '5,000'], ['삼성전자', '55,200'], ['안랩', '81,000'], ['케이엠더블..', '57,300'], ['피피아이', '12,600'], ['KT&G', '92,500'], ['삼성전자우', '45,600'], ['대양금속', '10,550'], ['SK하이닉스', '94,700'], ['SK텔레콤', '234,000']]\n",
      "10\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[['다우산업', '28,647.43'], ['나스닥', '9,015.03'], ['홍콩H', '11,320.56'], ['상해종합', '3,085.20'], ['니케이225', '23,656.62']]\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "import requests \n",
    "from bs4 import BeautifulSoup \n",
    "\n",
    "response = requests.get('https://crawlingstudy-dd3c9.web.app/03/')\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "# 인기 검색 종목 \n",
    "popular_tags = soup.select('ul.lst_pop > li') # list로 return \n",
    "# print(len(popular_tags))\n",
    "\n",
    "popular_list = []\n",
    "for li_tag in popular_tags:\n",
    "\n",
    "    event_name = li_tag.select_one('a').text\n",
    "    price = li_tag.select_one('span').text\n",
    "    \n",
    "    popular_list.append([event_name, price])\n",
    "\n",
    "print(popular_list)\n",
    "print(len(popular_list))\n",
    "print('-'*100)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 주요 해외 지수 \n",
    "major_tags = soup.select('ul.lst_major li') # list로 return \n",
    "# print(len(major_tags))\n",
    "\n",
    "major_list = []\n",
    "for li_tag in major_tags:\n",
    "\n",
    "    event_name = li_tag.select_one('a').text\n",
    "    price = li_tag.select_one('span').text\n",
    "    \n",
    "    major_list.append([event_name, price])\n",
    "\n",
    "print(major_list)\n",
    "print(len(major_list))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 5. 사이트내에 인기검색종목과 주요해외지수를 각각 크롤링하여 종목명과 상한, 하한 여부를 아래와 같이 리스트로 정리해주세요.\n",
    "\n",
    "결과 : \n",
    "[['써니전자', '상한'], ['삼성전자', '하한'], ['안랩', '상한'], ['케이엠더블..', '상한'], ['피피아이', '상한’], ['KT&G', '하한'], ['삼성전자우', '상한'], ['대양금속', '하한'], ['SK하이닉스', '상한'], ['SK텔레콤', '하한’]]\n",
    "\n",
    "[['다우산업', '상한'], ['나스닥', '상한'], ['홍콩H', '상한'], ['상해종합', '상한'], ['니케이225', '하한']]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['써니전자', '상한'], ['삼성전자', '하락'], ['안랩', '상승'], ['케이엠더블..', '상승'], ['피피아이', '상한'], ['KT&G', '하락'], ['삼성전자우', '상승'], ['대양금속', '하한'], ['SK하이닉스', '상승'], ['SK텔레콤', '하락']]\n",
      "10\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[['다우산업', '상한'], ['나스닥', '상한'], ['홍콩H', '상한'], ['상해종합', '상한'], ['니케이225', '하락']]\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "import requests \n",
    "from bs4 import BeautifulSoup \n",
    "\n",
    "response = requests.get('https://crawlingstudy-dd3c9.web.app/03/')\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "# 인기검색종목 \n",
    "# 종목명, 상한, 하한 여부 \n",
    "\n",
    "popular_tags = soup.select('#popularItemList > li')\n",
    "# print(len(popular_tags))\n",
    "# print(popular_tags)\n",
    "\n",
    "popular_list = []\n",
    "\n",
    "for tag in popular_tags:\n",
    "\n",
    "    event_name = tag.select_one('a').get_text()\n",
    "    upDown = tag.select_one('img').attrs['alt']\n",
    "\n",
    "    popular_list.append([event_name, upDown])\n",
    "\n",
    "print(popular_list)\n",
    "print(len(popular_list))\n",
    "print('-'*100)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 주요 해외 지수  \n",
    "# 종목명, 상한, 하한 여부 \n",
    "\n",
    "major_tags = soup.select('.lst_major > li')\n",
    "# print(len(major_tags))\n",
    "# print(major_tags)\n",
    "\n",
    "major_list = []\n",
    "\n",
    "for tag in major_tags:\n",
    "\n",
    "    event_name = tag.select_one('a').get_text()\n",
    "    upDown = tag.select_one('img').attrs['alt']\n",
    "\n",
    "    major_list.append([event_name, upDown])\n",
    "\n",
    "print(major_list)\n",
    "print(len(major_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 6. 사이트내에 인기검색종목과 주요해외지수를 각각 상한가인 종목만 크롤링하여 종목명과 주가지수를 아래와 같이 리스트로 정리해주세요.\n",
    "\n",
    "\n",
    "결과 : \n",
    "[['써니전자', '5,000'], ['안랩', '81,000'], ['케이엠더블..', '57,300'], ['피피아이', '12,600’], ['삼성전자우', '45,600'], ['SK하이닉스', '94,700’]]\n",
    "\n",
    "[['다우산업', '28,647.43'], ['나스닥', '9,015.03'], ['홍콩H', '11,320.56'], ['상해종합', '3,085.20']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "[['써니전자', '5,000'], ['안랩', '81,000'], ['케이엠더블..', '57,300'], ['피피아이', '12,600'], ['삼성전자우', '45,600'], ['SK하이닉스', '94,700']]\n"
     ]
    }
   ],
   "source": [
    "import requests \n",
    "from bs4 import BeautifulSoup \n",
    "\n",
    "response = requests.get('https://crawlingstudy-dd3c9.web.app/03/')\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "\n",
    "# 인기 검색 종목 \n",
    "popular_tags = soup.select('#popularItemList > li')\n",
    "popular_list = []\n",
    "\n",
    "for tag in popular_tags:\n",
    "    if (tag.select_one('img').attrs['alt'] == '상한') or (tag.select_one('img').attrs['alt'] == '상승'):\n",
    "        \n",
    "        event_name = tag.select_one('a').text\n",
    "        price = tag.select_one('span').text\n",
    "\n",
    "        popular_list.append([event_name, price])\n",
    "    continue\n",
    "\n",
    "print(len(popular_list))\n",
    "print(popular_list)\n",
    "print('-'*100)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 주요해외지수 \n",
    "major_tags = soup.select('.lst_major > li')\n",
    "major_list = []\n",
    "\n",
    "for tag in major_tags:\n",
    "    if (tag.select_one('img').attrs['alt'] == '상한') or (tag.select_one('img').attrs['alt'] == '상승'):\n",
    "        \n",
    "        event_name = tag.select_one('a').text\n",
    "        price = tag.select_one('span').text\n",
    "\n",
    "        major_list.append([event_name, price])\n",
    "    continue\n",
    "\n",
    "print(len(major_list))\n",
    "print(major_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 7. 분양중인 아파트 정보를 크롤링하여 아래와 같이 딕셔너리 형태로 정리 해주세요.\n",
    "- key : 이름, 보증금, 유형, 분양유형, 세대수, 평형 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myVenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
